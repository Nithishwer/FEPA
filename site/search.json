{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Getting Started with FEPA","text":"<p>FEPA (Free Energy Perturbation Analysis) is a Python package for analyzing molecular dynamics (MD) trajectories from FEP simulations, particularly ABFEs. FEPA allows you to visualize conformational changes and set up simulations to correct free energy estimates.</p> <p>This guide covers installation, basic usage, and key workflows.</p>","path":["Getting Started"],"tags":[]},{"location":"#installation","level":2,"title":"Installation","text":"<p>FEPA is must be installed from GitHub:</p> <pre><code>git clone https://github.com/Nithishwer/FEPA.git\ncd FEPA\npip install -e .\n</code></pre>","path":["Getting Started"],"tags":[]},{"location":"explanation/","level":1,"title":"Explanation section","text":"<p>Lorem Ipsum</p>","path":["Explanation"],"tags":[]},{"location":"reference/","level":1,"title":"Reference","text":"<p>This part of the project documentation focuses on an information-oriented approach. Use it as a reference for the technical implementation of the <code>calculator</code> project code.</p> <p>::: fepa.core.analyzers ::: fepa.core.dim_reducers ::: fepa.core.ensemble_handler ::: fepa.core.featurizers ::: fepa.core.visualizers</p>","path":["Reference"],"tags":[]},{"location":"how-to-guides/guide-1/","level":1,"title":"How-to-Guide","text":"<p>Put the example analysis in the how to guide section here</p>","path":["How-to-guides","How-to-Guide"],"tags":[]},{"location":"how-to-guides/guide-2/","level":1,"title":"How-to-Guide","text":"<p>Put the example analysis in the how to guide section here</p>","path":["How-to-guides","How-to-Guide"],"tags":[]},{"location":"tutorials/tutorial-1/","level":1,"title":"Featurizing ABFEs","text":"<p>This tutorial is designed to the user to introduce fepa by analyzing MD data from a set of simulations of the ligand 42922 (from the Deflorian et al set 1 datset) bound to the Orexin 2 Receptor. Specifically, we will compare the holo, apo and ABFE trajectories. Through this comparison, we will demonstrate that the protein’s binding pocket adopts distinct conformations between the final lambda windows (where the ligand is fully annihilated) of the ABFE simulation and the long apo simulation of the receptor.</p> <p>This tutorial is followed by Tutorial 2 where we will use FEPA to set up REUS simulations to estimate the free energy of this conformational change from the holo like  to apo like states. This tutorial uses MDAnalysis, MDtraj and the PENSA package for analysis, GROMACS for simulation and Plumed for enhanced sampling. It is assumed that the user is familiar with setting up and analyzing MD simulations run with GROMACS and Plumed. </p>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-1/#loading-the-config-file","level":2,"title":"Loading the config file","text":"<p>ABFE simulations produce multiple MD trajectories over different lamba windows. In our case, we have 44 lambda windows (11 Coulomb, 12 Restrains and 22 Van-der-Walls) plus the holo and the apo simulations that we have to analyse. To make things easier when parsing paths to the topology and coordinate files of these trajectories, we use a config file. The config file is json-formatted and contains all the information necessary to read the simulation trajectories. Here is a sample config file that I use for this tutorial:</p> <pre><code>{\n    \"base_path\": \"deflorian_set_1_j13_v1\",\n    \"abfe_window_path_template\": \"deflorian_set_1_j13_v1/OX2_{CMP_NAME}/abfe_van{REP_NO}_hrex_r{ABFE_REP_NO}/complex/{LEG_WINDOW}/{STAGE}\",\n    \"vanilla_path_template\": \"deflorian_set_1_j13_v1/OX2_{CMP_NAME}/vanilla_rep_{REP_NO}\",\n    \"apo_path_template\": \"deflorian_set_1_j13_v1/apo_OX2_r{REP_NO}\",\n    \"compounds\": [\n        \"42922\",\n    ],\n    \"pocket_residues_string\": \"12  54  57  58  59  60  61  62  63  64  65  70  71  78  81  82  83  85  86  89 138 142 160 161 162 163 175 178 179 182 183 232 235 236 239 240 242 243 261 265 268 269\"\n}\n</code></pre> <p>The pocket_residues_string variable is a string that stores the residue ids of all the proteins residue that have any atom within 6 A of the ligand. The JSON file is then loaded into a dictionary with the function <code>load_config</code> from <code>fepa.utils.file_utils</code></p>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-1/#loading-md-trajectories","level":2,"title":"Loading MD trajectories","text":"<p>Now that we have the template paths to all the simulations: Apo EQ, Holo EQ and ABFE, we can use the function <code>load_abfe_paths_for_compound</code> from fepa.utils.path_utils to generate a <code>path_dict</code> dictionary that contains all the MD file paths for a single compound as follows:</p> <pre><code>cmp = config['compounds'][0]\npath_dict = load_abfe_paths_for_compound(\n            config,\n            cmp,\n            van_list=[3], # Loading only vanilla simulation 3\n            leg_window_list=[f\"coul.{i:02d}\" for i in range(0, 11,2)] + [f'vdw.{i:02d}' for i in range(0, 21,2)] + [f'rest.{i:02d}' for i in range(0, 12,2)], # Loading only every other lambda window\n            bp_selection_string=\"name CA and resid \" + config[\"pocket_residues_string\"],\n            apo=True,\n        )\n</code></pre> <p>The <code>load_abfe_paths_for_compound</code> function has various arguments that allow the user control over what simulation paths are loaded. For more information, please refer to the API. </p> <p>Now that we have the path_dict, it is time for us to load the trajectories themselves. We will be using the EnsembleHandler class from fepa.core.ensemble_handler to do this. EnsembleHandler is a neat way of storing and manipulating the trajectories from multiple ensembles with some built in functions for sanity checks. Internally EnsembleHandler stores the trajectories as dictionary of MDA universes.  </p> <p>TODO: Need to remove ensemblehandler and just use universe dict</p> <pre><code># Load trajectories\nensemble_handler = EnsembleHandler(path_dict)\n# Make universes\nensemble_handler.make_universes()\nlogging.info(\"Making universes for compound %s...\", cmp)\n# Check for BP residue consistency across all the trajectories\nlogging.info(\"Checking residue consistency for compound %s...\", cmp)\n</code></pre>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-1/#featurizing-md-trajectories","level":2,"title":"Featurizing MD trajectories","text":"<p>We will now be featurizing these trajectories by their pairwise C-alpha distances in the binding pocket using the function <code>SelfDistanceFeaturizer</code> from <code>fepa.core.featurizers</code>. <code>SelfDistanceFeaturizer</code> computes and stored all possible pairs of distances between the C-alpha atoms of the binding pocket residues. The class also has <code>save_features</code> and <code>load_features</code> functions that help save the features as a csv file to make sure the time consuming featurization step need not be repeated every run.</p> <p>TODO: Make sure the binding pocket selection is consistent</p> <pre><code># Make a folder for the analysis output\ncmp_run_dir = f'analysis/{cmp}/'\nif !(os.path.exists(cmp_run_dir)):\n    os.mkdir(cmp_run_dir)\n\n# Featurize and save features\nfeaturizer = SelfDistanceFeaturizer(ensemble_handler)\nfeaturizer.featurize()\nfeaturizer.save_features(input_dir=cmp_existing_run_dir)\n</code></pre>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-1/#visualizing-ensembles","level":2,"title":"Visualizing ensembles","text":"<p>Saving the features in a csv format gives us the flexibility to analyse it as required. For the purpose of this tutorial, we will be looking at how our features capture the difference between the apo, the holo and the abfe ensembles. To do this we reduce the dimensions of the features data using the <code>PCADimReducer</code> class from <code>fepa.core.dim_reducers</code>. FEPA also supports other dimensionality reduction techniqeus like UMAP and tSNE. In fact UMAP is better able to resolve the differences in binding pocket configurations between different ensembles. We will be doing PCA here as it also doubles up as a nice CV to bias when performing umbrella sampling later.</p> <pre><code># Dimensionality Reduction\nlogging.info(\"Performing dimensionality reduction for compound %s...\", cmp)\ndimreducer = PCADimReducer(featurizer.get_feature_df(), n_components=8)\ndimreducer.reduce_dimensions()\ndimreducer.calculate_projections()\ndimreducer.save_projection_df(\n    save_path=os.path.join(cmp_output_dir, \"pca_projection_df.csv\")\n)\n</code></pre> <p>First we plot the eigen values of all the PCs to understand what percentage of variance is captured by the first few PCs:</p> <pre><code>logging.info(\"Plotting PCA eigenvalues for compound %s...\", cmp)\nplot_eigenvalues(\n    pca_object=dimreducer.get_pca(),\n    n_components=8,\n    save_path=os.path.join(cmp_output_dir, \"eigenvalues.png\"),\n)\n</code></pre> <p></p> <p>Figure 1: PCA eigenvalues for the binding-pocket Cα self-distance features.</p> <p>Here, most of the variance is captured by PC1. However, this may not always be the case. Therefore, for this tutorial, we will use PC1 and PC2 together, as they collectively capture the majority of the variance. To improve visualization, we define a new column in <code>projection_df</code> called <code>simtype</code>, which groups the ensembles into broader categories: <code>abfe_coul</code>, <code>abfe_vdw</code>, <code>abfe_rest</code>, <code>holo_equil</code>, <code>apo</code>, and <code>nvt</code>.</p> <pre><code># Further labelling the ensembles\nprojection_df = dimreducer.get_pca_projection_df()\n# Add another column called simtype based on ensemble\ndef get_simtype(ensemble_name: str) -&gt; str:\n    if \"van\" in ensemble_name:\n        if 'nvt' in ensemble_name:\n            return \"nvt\"\n        if \"coul\" in ensemble_name:\n            return \"abfe_coul\"\n        elif \"vdw\" in ensemble_name:\n            return \"abfe_vdw\"\n        elif \"rest\" in ensemble_name:\n            return \"abfe_rest\"\n        else:\n            return \"holo_equil\"\n    elif \"apo\" in ensemble_name:\n        return \"apo\"\n    else:\n        return \"other\"\nprojection_df[\"simtype\"] = projection_df[\"ensemble\"].apply(get_simtype)\n</code></pre> <p>We can visualize the dimensionality-reduced data using the <code>DimRedVisualizer</code> class. In the example below, we plot the first two principal components, colored by simulation and time. We also highlight NVT, as it represents the initial crystal structure after energy minimization.</p> <pre><code>logging.info(\"Visualizing compound %s...\", cmp)\ndimred_visualizer = DimRedVisualizer(projection_df=projection_df, data_name=\"PCA\")\ndimred_visualizer.plot_dimred_sims(\n    save_path=os.path.join(cmp_run_dir, \"pca_components_ensemble_noapo.png\"),\n    highlights=[f\"{cmp}_nvt\"],\n)\ndimred_visualizer.plot_dimred_time(\n    save_path=os.path.join(cmp_run_dir, \"pca_components_time_noapo.png\")\n)\ndimred_visualizer.plot_dimred_sims(\n    column=\"simtype\",\n    save_path=os.path.join(cmp_run_dir, \"pca_components_simtype.png\"),\n)\n</code></pre> <p> Figure 2: Simulation frames in PC-space (PC1 vs PC2), colored by simtype</p>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-1/#clustering-ensembles","level":2,"title":"Clustering ensembles","text":"<p>In Figure 2, frames from the ABFE simulations closely resemble those from the holo equilibrium simulation, forming two distinct clusters: apo-like and holo-like. We will be clustering them using <code>cluster_pca</code>. After clustering, we can estimtate the data point that is closest to the center with the function <code>make_ensemble_center_df</code> which returns a <code>DataFrame</code> containing the details of the frame closest to the centroid in PC space. </p> <pre><code># Cluster the projection df\npca_projection_df_clustered = cluster_pca(\n    projection_df, n_clusters=3, n_components=3\n)\n# Ensemble center df\nensemble_center_df = make_ensemble_center_df(\n    pca_projection_df_clustered, key=\"cluster\"\n)\n</code></pre> <p>We then visualize the clustered data with ensemble centers as follows:</p> <pre><code># Visualization of clustered data\ndimred_visualizer_clustered = DimRedVisualizer(\n    projection_df=pca_projection_df_clustered, data_name=\"PCA\"\n)\ndimred_visualizer_clustered.plot_dimred_cluster(\n    save_path=os.path.join(\n        cmp_run_dir, \"subset_pca_components_clusters_w_center.png\"\n    ),\n    centroid_df=ensemble_center_df,\n    cluster_column=\"cluster\",\n)\n</code></pre> <p></p> <p>Figure 3: Clustered PCA data with ensemble centers marked by an X.</p>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-1/#visualizing-differences-across-clustered-ensembles","level":2,"title":"Visualizing differences across clustered ensembles","text":"<p>With two distinct clusters identified, we can compare them across different features by computing the Jensen–Shannon (JS) entropy for each feature. The code below plots feature-wise histograms for cluster 0 and cluster 1, annotated with their JS entropy values:</p> <pre><code># Copy the cluster labels from pca_projection_df_clustered to feature_df\nfeature_df_w_clusters = featurizer.get_feature_df().copy()\nfeature_df_w_clusters[\"cluster\"] = pca_projection_df_clustered[\"cluster\"].values\n\n\n# Compute feature-level histograms and JS entropy between clusters 0 and 1\nhistograms = compute_histograms(\n    feature_df_w_clusters,\n    \"cluster\",\n    0,\n    1,\n    num_bins=50,\n    feature_column_keyword=\"DIST\",\n)\n\nrel_ent_dict = compute_relative_entropy(\n    feature_df_w_clusters,\n    ensemble1=0,\n    ensemble2=1,\n    num_bins=50,\n    key=\"cluster\",\n    feature_column_keyword=\"DIST\",\n)\n\nplot_jsd_histograms(\n    histograms,\n    rel_ent_dict,\n    top_n=16,\n    save_path=os.path.join(cmp_run_dir, \"jsd_cluster0_vs_cluster1.png\"),\n)\n</code></pre> <p> Figure 4: Histograms of the top 16 features showing the highest Jensen–Shannon divergence between clusters 0 and 1.</p> <p>We then save the ensemble center frames as GRO files to compare structures in molecular visualization tools such as PyMOL:</p> <pre><code># Save ensemble center frames as GRO files\nfor _, row in ensemble_center_df.iterrows():\n    center_ensemble = row[\"ensemble\"]\n    center_timestep = row[\"timestep\"]\n    print(f\"Ensemble: {center_ensemble}, Timestep: {center_timestep}\")\n\n    # Load trajectories\n    ensemble_handler.make_universes()\n\n    # Export the frame corresponding to the ensemble center\n    ensemble_handler.dump_frames(\n        ensemble=center_ensemble,\n        timestep=center_timestep,\n        save_path=f\"subset_cluster_{int(row['cluster'])}_center.gro\",\n    )\n</code></pre>","path":["Tutorials","Featurizing ABFEs"],"tags":[]},{"location":"tutorials/tutorial-2/","level":1,"title":"Setting up REUS","text":"<p>In Tutorial 2, we build on the concepts learned in Tutorial 1, where the apo and holo states were shown to form distinct conformational clusters. Using the data provided in the [template], we will set up Replica Exchange Umbrella Sampling (REUS) simulations to estimate the free energy of the conformational transition from holo to apo, using the principal component (PC) 1 as the collective variable (CV). We will achieve this by morphing the protein from one state to another, equilibrating the system, and then running REUS to sample the transition.</p>","path":["Tutorials","Setting up REUS"],"tags":[]},{"location":"tutorials/tutorial-2/#preparing-the-plumeddat-file","level":2,"title":"Preparing the plumed.dat file","text":"<p>The first step in performing umbrella sampling with GROMACS and PLUMED is to create a plumed.dat file that defines the collective variable (CV), and the positions of the umbrella sampling restraints. To do this, we load the feature CSV files, initialize a DimReducer object, and extract the corresponding PCA object to define the CV based on pairwise Cα distances.</p> <pre><code># Load Features df and reduce dimensions\nfeature_df = pd.read_csv(os.path.join(\"md_data\", \"top_features_apo_vdw.20.csv\"))\ndimreducer = PCADimReducer(feature_df, n_components=8)\ndimreducer.reduce_dimensions()\ndimreducer.calculate_projections()\npca_projection_df = dimreducer.get_pca_projection_df()\n# Use PCA from dimreducer to write plumed file\ntop_features = feature_df.filter(regex=\"DIST\", axis=1).columns\nwrite_plumed_file(\n    sdf_names=top_features,\n    top_features_pca=dimreducer.get_pca(),\n    save_path=\"plumed.dat\",\n    molinfo_structure=\"../reference.pdb\",  # fix molinfo here\n)\n</code></pre> <p>The PLUMED input file should look like this:</p> <p><pre><code>MOLINFO STRUCTURE=../reference.pdb\nd1: DISTANCE ATOMS=@CA-236,@CA-243\nd2: DISTANCE ATOMS=@CA-175,@CA-243\nd3: DISTANCE ATOMS=@CA-138,@CA-243\n.\n.\n.\nd200: DISTANCE ATOMS=@CA-61,@CA-70\n# Create the dot product\ndot: COMBINE ARG=d1,d2,d3...d200 COEFFICIENTS=0.095,0.152,0.133...0.057,0.054,0.032 PERIODIC=NO\nCV: MATHEVAL ARG=dot FUNC=10*x PERIODIC=NO\nPRINT ARG=CV FILE=COLVAR STRIDE=1\n# Put position of restraints here for each window\nrestraint: RESTRAINT ARG=CV AT=@replicas:$RESTRAINT_ARRAY KAPPA=$KAPPA\nPRINT ARG=restraint.* FILE=restr\n</code></pre> Note that $RESTRAINT_ARRAY is a placeholder for the harmonic restraint positions in CV space. When defining these positions, ensure they align with the direction of the structural morph. By convention, we transition from vdw.20 to apo structures. To assign restraints correctly, identify the ensemble with the lowest PC value and order the restraints from min to max (or vice versa) accordingly.</p> <pre><code># Pair of ensembles to compare\npair = (\"vdw.20\", \"apo\")\n# Get mean PC1 for the two ensembles\nmean_pc1_ensemble1 = pca_projection_df[pca_projection_df[\"state\"] == pair[0]][\n    \"PC1\"\n].mean()\nmean_pc1_ensemble2 = pca_projection_df[pca_projection_df[\"state\"] == pair[1]][\n    \"PC1\"\n].mean()\nlogging.info(\n    f\"Mean PC1 for {pair[0]}: {mean_pc1_ensemble1}, Mean PC1 for {pair[1]}: {mean_pc1_ensemble2}\"\n)\n# Get the restraint array based on the two ensembles\nPC1_min = pca_projection_df[\"PC1\"].min()\nPC1_max = pca_projection_df[\"PC1\"].max()\n# If min PC1 is from ensemble 1, then the restraint array should be from PC1_min to PC1_max\nif mean_pc1_ensemble1 &lt; mean_pc1_ensemble2:\n    restraint_array = np.linspace(PC1_min, PC1_max, 24)\nelif mean_pc1_ensemble1 &gt; mean_pc1_ensemble2:\n    restraint_array = np.linspace(PC1_max, PC1_min, 24)\n</code></pre> <p>Once the restraint array is prepared, we write it to the PLUMED file using the write_plumed_restraints function:</p> <pre><code># Write the restraint array to the plumed file\nwrite_plumed_restraints(\n    plumed_file=\"plumed.dat\",\n    restraint_centers=restraint_array,\n    kappa=5,\n)\n</code></pre> <p>The restrain line on plumed.dat file must now be an array of distance restraints that looks like this:</p> <pre><code>restraint: RESTRAINT ARG=CV AT=@replicas:116.856,119.047,121.239...167.262 KAPPA=5\n</code></pre>","path":["Tutorials","Setting up REUS"],"tags":[]},{"location":"tutorials/tutorial-2/#morphing-with-memento","level":2,"title":"Morphing with memento","text":"<p>For this tutorial, the GRO files representing the vdw.20 and apo states are provided in the data folder, prepared in the same way as in Tutorial 1. The plumed.dat file has also been prepared. The next step for REUS is to generate intermediate protein conformations using Memento (JCTC, 2023) . FEPA provides a class for easy access to Memento.</p> <p>Using FEPA’s <code>memento_workflow</code> class, we can perform the protein morphing. A Memento directory is needed to store morphs for each entry in initial_target_gro_dict, and an apo_template path must be provided, containing the topology and MDP files required for equilibrium simulations.</p> <pre><code># Declaring variables:\nmemento_dir = \"/biggin/b211/reub0138/Projects/orexin/deflorian_set_1_j13_v1_memento\"\n# Defining pairs\npair = (\"all_vdw20\", \"apo_3\")\nall_vdw20_gro_file = \"/biggin/b211/reub0138/Projects/orexin/deflorian_set_1_j13_v1/analysis/a12_dimreduce_vdw.20/subset_cluster_1_center.gro\"\napo_3_gro_file = \"/biggin/b211/reub0138/Projects/orexin/deflorian_set_1_j13_v1/analysis/a12_dimreduce_vdw.20/subset_cluster_2_center.gro\"\ntemplate_path = \"/biggin/b211/reub0138/Projects/orexin/deflorian_set_1_j13_v1_memento/apo_template\"  # Make sure no water and no ions in the template topology file\n# Setup Memento folders\nmemento_flow = memento_workflow(\n    memento_dir=memento_dir,\n    initial_gro=all_vdw20_gro_file,\n    target_gro=apo_3_gro_file,\n    initial_name=pair[0],\n    target_name=pair[1],\n    template_path=template_path,\n    run_name=\"memento_run_v1\",\n    n_residues=296,\n)\n</code></pre> <p>We can use the workflow functions to perform each step. First, <code>prepare_memento</code> sets up the files required by Memento. Then, <code>run_memento</code> executes the morphing. <code>run_memento</code> requires the protonation states of all histidines in the format expected by GROMACS pdb2gmx (0 for HID, 1 for HIE, 2 for HIP, 3 for HIS1). Additionally, the indices of CYX residues must be provided, as Memento cannot process them automatically.</p> <pre><code># Preparing memento input\nmemento_flow.prepare_memento()\n# Running memento\nmemento_flow.run_memento(\n    template_path=template_path,\n    last_run=\"memento_run_v1\",\n    protonation_states=[1, 1, 1, 2, 1, 2],\n    cyx_residue_indices = []\n)\n</code></pre>","path":["Tutorials","Setting up REUS"],"tags":[]},{"location":"tutorials/tutorial-2/#running-equilibration","level":2,"title":"Running Equilibration","text":"<p>This step may take some time. Once complete, we can set up equilibration simulations with Memento by providing a job script path, which can be modified to suit the specific HPC system.</p> <pre><code># Running analysis\nmemento_flow.prepare_equil_simulations(\n    job_script_template=\"/biggin/b211/reub0138/Projects/orexin/lenselink_a2a_memento_v1/job_vanilla_ranv_equil_arr_template.sh\"\n)\n</code></pre> <p>After running prepare_equil_simulations, individual boxes for each morph are created. We then simulate each box to relax the side chains by submitting the job to our HPC. Once complete, we can proceed to the REUS simulations.</p>","path":["Tutorials","Setting up REUS"],"tags":[]},{"location":"tutorials/tutorial-2/#preparing-reus","level":2,"title":"Preparing REUS","text":"<p>Once the equilibration simulations are complete, use FEPA’s <code>reus_umbrella_sampling_workflow</code> class to set up umbrella sampling in the same working directory. The number of windows can be adjusted via <code>n_windows</code> (24 is typically sufficient). If the residue IDs in the plumed.dat file does not match those in the MD GRO files, FEPA requires the correct offset to be set via the <code>plumed_resid_offset</code> parameter.</p> <pre><code>import logging\nfrom pathlib import Path\nfrom fepa.flows.reus_flows import (\n    reus_umbrella_sampling_workflow,\n)\n\nsim_path = \"wdir/all_vdw20_apo_3/memento_run_v1/wdir/boxes/sim0\"\nwdir_path = Path(sim_path).parents[1]\nplumed_path = \"plumed.dat\"\nsimname = \"all_vdw20_apo_3\"\ninitial_gro = \"md_data/cluster_1_center.gro\"\nfinal_gro = \"md_data/cluster_2_center.gro\"\nsubmission_script_template_arr = \"md_data/job_reus_template.sh\"\nprint(f\"wdir_path: {wdir_path}, plumed_path: {plumed_path}\")\numbrella_sampler = reus_umbrella_sampling_workflow(\n    wdir_path=wdir_path,\n    plumed_path=plumed_path,\n    submission_script_template_arr=submission_script_template_arr,\n    start=simname.split(\"_\")[0] + \"_\" + simname.split(\"_\")[1],\n    end=simname.split(\"_\")[2] + \"_\" + simname.split(\"_\")[3],\n    reus_folder_name=\"reus_v1\",\n    n_windows=24,\n    plumed_resid_offset=0,\n    initial_gro=initial_gro,\n    target_gro=final_gro,\n)\numbrella_sampler.setup_simulations(exist_ok=True)\n</code></pre>","path":["Tutorials","Setting up REUS"],"tags":[]},{"location":"tutorials/tutorial-2/#analyzing-reus","level":2,"title":"Analyzing REUS","text":"<p>Once your REUS system is set up, you can analyze the results using the workflow:</p> <pre><code>umbrella_sampler.prepare_wham()\numbrella_sampler.run_wham()\numbrella_sampler.analyse_us_hist(range=(90, 180), colvar_prefix=\"COLVAR\")\numbrella_sampler.get_initial_final_CVs()\numbrella_sampler.plot_free_energies(\n    units=\"kcal\",\n)\n</code></pre> <p>This prepares and runs WHAM on the histograms and generates the free energy curves.</p> <p></p> <p>Figure 1: Free energy curves from the tutorial simulations. The CV values of apo and holo structures are marked with gray dotted lines. Different lines represent curves computed using varying proportions of data to assess convergence.</p>","path":["Tutorials","Setting up REUS"],"tags":[]}]}